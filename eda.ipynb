{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "#train_ex = pd.read_csv('training_extra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prices larger than 150 are capped at 150\n",
    "# bunch of nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df = df.copy(deep=True)\n",
    "    df['Size'] = df['Size'].fillna('Medium') #assume medium to be mean\n",
    "    size_mapping = {'Small': 0, 'Medium': 1, 'Large': 2}\n",
    "    \n",
    "    df['Size'] = df['Size'].map(size_mapping)\n",
    "\n",
    "    df['Weight Capacity (kg)'] = df['Weight Capacity (kg)'].fillna(df['Weight Capacity (kg)'].mean())\n",
    "    \n",
    "\n",
    "    dummies = pd.get_dummies(df[['Compartments', 'Material', 'Brand','Style', 'Color','Laptop Compartment','Waterproof']], dummy_na=True)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop(['Compartments', 'Material', 'Brand','Style', 'Color','Laptop Compartment','Waterproof'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform2(df):\n",
    "    df = df.copy(deep=True)\n",
    "    df['Size'] = df['Size'].fillna('Medium') #assume medium to be mean\n",
    "    size_mapping = {'Small': 0, 'Medium': 1, 'Large': 2}\n",
    "    \n",
    "    df['Size'] = df['Size'].map(size_mapping)\n",
    "\n",
    "    df['Weight Capacity (kg)'] = df['Weight Capacity (kg)'].fillna(df['Weight Capacity (kg)'].mean())\n",
    "    \n",
    "\n",
    "    dummies = pd.get_dummies(df[['Compartments', 'Material', 'Brand','Style', 'Color','Laptop Compartment','Waterproof']], dummy_na=True)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop(['id','Compartments', 'Material', 'Brand','Style', 'Color','Laptop Compartment','Waterproof'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def quantile_transform(df):\n",
    "    quantile = QuantileTransformer(output_distribution='normal', quantiles=[i/10 for i in range(10+1)])\n",
    "    return quantile.fit_transform(df[['Price']]), quantile\n",
    "def reverse_quantile_transform(pred, quantile):\n",
    "    return quantile.inverse_transform(pred.reshape(-1,1))\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "def discretize_transform(df):\n",
    "    discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "    return discretizer.fit_transform(df[['Price']]), discretizer\n",
    "\n",
    "def reverse_discretize_transform(pred, discretizer): \n",
    "    return discretizer.inverse_transform(pred.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainT = transform(train)\n",
    "#trainT = trainT.loc[(trainT['Price'] <= 149)&(trainT['Price'] >= 16)] #remove prices larger than 150\n",
    "# try1, without large values lgb and linear regression just predict mean\n",
    "testT = transform(test)\n",
    "\n",
    "trainT['TPrice'], quantile = discretize_transform(trainT)\n",
    "target = 'TPrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainT.TPrice.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Price'] = train['Price'].mean()\n",
    "test[['id', 'Price']].to_csv('mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analytics\n",
    "- nothing obvious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat = trainT.corr()\n",
    "corrMat['Price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each feature in the train dataframe\n",
    "non_categorical_features = train.select_dtypes(exclude=['object', 'category']).columns\n",
    "\n",
    "for feature in non_categorical_features:\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(train[feature], train['Price'], alpha=0.005)\n",
    "    plt.title(f'Scatter Plot of {feature} vs Price')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only categorical features\n",
    "categorical_features = train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Iterate over each categorical feature\n",
    "for feature in categorical_features:\n",
    "    # Create a violin plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.violinplot(x=feature, y='Price', data=train, split=True)\n",
    "    plt.title(f'Violin Plot of {feature} vs Price')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target transformation\n",
    "- quantile transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Price'] < 16,'Price'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(train['Price']).hist(bins=100) \n",
    "#log, sqrt, .. nothing really nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# Assuming 'y' is your target variable\n",
    "quantile = QuantileTransformer(output_distribution='normal')\n",
    "train['price_quantile'] = quantile.fit_transform(train[['Price']])\n",
    "\n",
    "train['price_quantile'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_scores = []\n",
    "models = {}\n",
    "for i, (train_index, test_index) in enumerate(kf.split(trainT)):\n",
    "    X_train, X_test = trainT.drop('Price', axis=1).iloc[train_index], trainT.drop('Price', axis=1).iloc[test_index]\n",
    "    y_train, y_test = trainT['Price'].iloc[train_index], trainT['Price'].iloc[test_index]\n",
    "    \n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    models[f'model_{i}'] = model\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "print(\"Average RMSE across all folds:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_scores = []\n",
    "models = {}\n",
    "for i, (train_index, test_index) in enumerate(kf.split(trainT)):\n",
    "    X_train, X_test = trainT.drop('Price', axis=1).iloc[train_index], trainT.drop('Price', axis=1).iloc[test_index]\n",
    "    y_train, y_test = trainT['Price'].iloc[train_index], trainT['Price'].iloc[test_index]\n",
    "    \n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    models[f'model_{i}'] = model\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "print(\"Average RMSE across all folds:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_scores = []\n",
    "models = {}\n",
    "for i, (train_index, test_index) in enumerate(kf.split(trainT)):\n",
    "    X_train, X_test = trainT.drop('Price', axis=1).iloc[train_index], trainT.drop('Price', axis=1).iloc[test_index]\n",
    "    y_train, y_test = trainT['Price'].iloc[train_index], trainT['Price'].iloc[test_index]\n",
    "    \n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    models[f'model_{i}'] = model\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "print(\"Average RMSE across all folds:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(testT)\n",
    "    test_predictions[model_name] = y_pred\n",
    "\n",
    "test_predictions_df = pd.DataFrame(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df['mean'] = test_predictions_df.mean(axis=1)\n",
    "test_predictions_df['mean'].to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Create a dataframe with the coefficients and feature names\n",
    "importance_df = pd.DataFrame({'feature': X_train.columns, 'coefficient': coefficients})\n",
    "\n",
    "# Sort the dataframe by absolute coefficient value\n",
    "importance_df = importance_df.sort_values(by='coefficient', ascending=False)\n",
    "\n",
    "# Print the top 5 most important features\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression quantile transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_scores = []\n",
    "rmse_scores_original = []\n",
    "models = {}\n",
    "results = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(trainT)):\n",
    "    X_train, X_test = trainT.drop(['Price', 'TPrice'], axis=1).iloc[train_index], trainT.drop(['Price', 'TPrice'], axis=1).iloc[test_index]\n",
    "    y_train, y_test = trainT['TPrice'].iloc[train_index], trainT['TPrice'].iloc[test_index]\n",
    "    \n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    models[f'model_{i}'] = model\n",
    "    y_predO = reverse_quantile_transform(model.predict(X_test), quantile).flatten()\n",
    "    y_testO = trainT['Price'].iloc[test_index]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "    rmseO = np.sqrt(mean_squared_error(y_testO, y_predO))\n",
    "    rmse_scores_original.append(rmseO)\n",
    "\n",
    "    # Log results\n",
    "    res = pd.DataFrame({'y_testT': y_test, 'y_predT': y_pred, 'y_testO': y_testO, 'y_predO': y_predO})\n",
    "    results.append(res)\n",
    "\n",
    "results = pd.concat(results, ignore_index=True)\n",
    "print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "print(\"Average RMSE across all folds:\", np.mean(rmse_scores))\n",
    "print(\"RMSE scores for each fold original:\", rmse_scores_original)\n",
    "print(\"Average RMSE across all folds original:\", np.mean(rmse_scores_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['y_testT','y_predT']].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "plt.hist(results['y_predT'], bins=50, alpha=0.5, label='Prediction')\n",
    "plt.hist(results['y_testT'], bins=50, alpha=0.5, label='Ground Truth')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Histograms of Predictions and Ground Truths')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(testT)\n",
    "    y_predo = reverse_quantile_transform(model.predict(testT), quantile).flatten()\n",
    "    test_predictions[model_name] = y_predo\n",
    "\n",
    "test_predictions_df = pd.DataFrame(test_predictions)\n",
    "\n",
    "test_predictions_df['mean'] = test_predictions_df.mean(axis=1)\n",
    "test_predictions_df[['mean']].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df['Price'] = test_predictions_df['mean']\n",
    "test_predictions_df['id'] = test['id']\n",
    "test_predictions_df[['id', 'Price']].to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgb regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Train and store each model\n",
    "for i, (train_index, test_index) in enumerate(kf.split(trainT)):\n",
    "    X_train, X_test = trainT.drop('Price', axis=1).iloc[train_index], trainT.drop('Price', axis=1).iloc[test_index]\n",
    "    y_train, y_test = trainT['Price'].iloc[train_index], trainT['Price'].iloc[test_index]\n",
    "    \n",
    "    model = lgb.LGBMRegressor(objective='regression_l2', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    models[f'model_{i}'] = model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "print(\"Average RMSE across all folds:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(testT)\n",
    "    test_predictions[model_name] = y_pred\n",
    "\n",
    "test_predictions_df = pd.DataFrame(test_predictions)\n",
    "test_predictions_df['mean'] = test_predictions_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df['mean'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgb regressor quantile transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_scores = []\n",
    "rmse_scores_original = []\n",
    "models = {}\n",
    "results = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(trainT)):\n",
    "    X_train, X_test = trainT.drop(['Price', 'TPrice'], axis=1).iloc[train_index], trainT.drop(['Price', 'TPrice'], axis=1).iloc[test_index]\n",
    "    y_train, y_test = trainT['TPrice'].iloc[train_index], trainT['TPrice'].iloc[test_index]\n",
    "    \n",
    "\n",
    "    model = lgb.LGBMRegressor(objective='regression_l2', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    models[f'model_{i}'] = model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    models[f'model_{i}'] = model\n",
    "    y_predO = reverse_quantile_transform(model.predict(X_test), quantile).flatten()\n",
    "    y_testO = trainT['Price'].iloc[test_index]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "    rmseO = np.sqrt(mean_squared_error(y_testO, y_predO))\n",
    "    rmse_scores_original.append(rmseO)\n",
    "\n",
    "    # Log results\n",
    "    res = pd.DataFrame({'y_testT': y_test, 'y_predT': y_pred, 'y_testO': y_testO, 'y_predO': y_predO})\n",
    "    results.append(res)\n",
    "\n",
    "results = pd.concat(results, ignore_index=True)\n",
    "print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "print(\"Average RMSE across all folds:\", np.mean(rmse_scores))\n",
    "print(\"RMSE scores for each fold original:\", rmse_scores_original)\n",
    "print(\"Average RMSE across all folds original:\", np.mean(rmse_scores_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['y_testT','y_predT']].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['y_testO','y_predO']].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict price of 150 / using discretized output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainT['target'] = trainT['Price']> 149\n",
    "target = 'TPrice'\n",
    "trainT[target].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainT.drop(['Price', 'TPrice'], axis=1), trainT['TPrice'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a LightGBM multiclass classifier\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "params = {'objective': 'multiclass', 'num_class': len(np.unique(y_train)), 'metric': 'multi_logloss', 'boosting_type': 'gbdt', 'num_leaves': 31, 'learning_rate': 0.05}\n",
    "model = lgb.train(params, train_data, num_boost_round=100)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
